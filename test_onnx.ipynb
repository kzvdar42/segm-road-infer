{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "                               \r"
     ]
    }
   ],
   "source": [
    "from nvidia.dali import pipeline_def, Pipeline\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from utils import get_subfolders_with_files, is_image\n",
    "\n",
    "image_dir = \"../test-data/\"\n",
    "filenames = list(get_subfolders_with_files(image_dir, is_image, yield_by_one=True))\n",
    "len(filenames)\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['DALI_DISABLE_NVML'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export DALI_DISABLE_NVML=1\n",
    "# export DALI_RESTRICT_PINNED_MEM=1\n",
    "from nvidia.dali import pipeline_def\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "max_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline_def\n",
    "def get_dali_image_pileline(filenames, labels, width, height, mean=None, std=None):\n",
    "    jpegs, labels = fn.readers.file(files=filenames, labels=labels)\n",
    "    images = fn.decoders.image(jpegs, device='mixed')\n",
    "    shape = fn.shapes(images)\n",
    "    images = fn.resize(images, resize_x=width, resize_y=height)\n",
    "    if mean is not None or std is not None:\n",
    "        print(f'Using mean: {mean} std: {std}')\n",
    "        mean_ = np.array([[mean]]) if mean is not None else None\n",
    "        std_ = np.array([[std]]) if std is not None else None\n",
    "        images = fn.normalize(images, mean=mean_, stddev=std_)\n",
    "    images = fn.transpose(images, perm=[2, 0, 1])\n",
    "    return images, labels, shape[0], shape[1]\n",
    "\n",
    "\n",
    "\n",
    "# def get_dali_dataloader(filename_to_id, model_cfg):\n",
    "#     pipe = get_dali_image_pileline(\n",
    "#         filenames=list(filename_to_id.keys()), labels=list(filename_to_id.values()),\n",
    "#         width=model_cfg.input_shape[0], height=model_cfg.input_shape[1],\n",
    "#         mean=model_cfg.img_mean, std=model_cfg.img_std,\n",
    "#         batch_size=model_cfg.batch_size, num_threads=model_cfg.num_workers, device_id=0\n",
    "#     )\n",
    "#     pipe.build()\n",
    "#     return DALIGenericIterator([pipe], ['images', 'filename_map', 'height', 'width'])\n",
    "\n",
    "batch_size=1\n",
    "sequence_length=8\n",
    "initial_prefetch_size=11\n",
    "shuffle=True\n",
    "n_iter=6\n",
    "\n",
    "@pipeline_def\n",
    "def video_pipe(filename):\n",
    "    video, labels, start_frame_num = fn.readers.video(device=\"gpu\", filenames=[filename], labels=[], sequence_length=sequence_length,\n",
    "                                     random_shuffle=False, image_type=types.RGB, dtype=types.FLOAT, initial_fill=initial_prefetch_size, enable_frame_num=True)\n",
    "    shapes = fn.shapes(video)[1:3]\n",
    "    video = fn.resize(video, size=[2048, 1024], device=\"gpu\")\n",
    "    video = fn.crop_mirror_normalize(video, output_layout=\"FCHW\", mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], image_type=types.RGB, device=\"gpu\")\n",
    "    return video, shapes, start_frame_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/nvidia/dali/fn.py:76: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.\n",
      "  return op_class(**init_args)(*inputs, **call_args)\n",
      "[/opt/dali/dali/operators/reader/loader/video_loader.h:178] ``file_list_include_preceding_frame`` is set to False (or not set at all). In future releases, the default behavior would be changed to True.\n"
     ]
    }
   ],
   "source": [
    "pipe = video_pipe(filename='src_cfr_test.mp4', batch_size=batch_size, num_threads=2, device_id=0, seed=12345)\n",
    "pipe.build()\n",
    "\n",
    "dali_iter = DALIGenericIterator([pipe], ['images', 'shapes', 'start_frame_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24]]\n",
      "torch.Size([8, 3, 2048, 1024])\n",
      "[{'height': 1080, 'width': 1920, 'image_path': '00024.jpg'}, {'height': 1080, 'width': 1920, 'image_path': '00025.jpg'}, {'height': 1080, 'width': 1920, 'image_path': '00026.jpg'}, {'height': 1080, 'width': 1920, 'image_path': '00027.jpg'}, {'height': 1080, 'width': 1920, 'image_path': '00028.jpg'}, {'height': 1080, 'width': 1920, 'image_path': '00029.jpg'}, {'height': 1080, 'width': 1920, 'image_path': '00030.jpg'}, {'height': 1080, 'width': 1920, 'image_path': '00031.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dali_iter):\n",
    "    batch = data[0]\n",
    "    images = batch['images'].squeeze()\n",
    "    start_frame_num = batch['start_frame_num'].cpu().numpy()\n",
    "    shapes = batch['shapes'].cpu().numpy()\n",
    "    img_masks = None\n",
    "    metadata = []\n",
    "    for first_frame_num, shape in zip(start_frame_num, shapes):\n",
    "        for off in range(images.shape[0] // len(shapes)):\n",
    "            n_frame = first_frame_num.item() + off\n",
    "            metadata.append({\n",
    "                \"height\": shape[0], \"width\": shape[1], \"image_path\": f'{n_frame:0>5}.jpg',\n",
    "            })\n",
    "    print(images.shape)\n",
    "    print(metadata)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def show_sequence(sequence, label):\n",
    "    columns = 1\n",
    "    rows = (sequence_length + 1) // (columns)\n",
    "    fig = plt.figure(figsize = (32,(16 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows*columns-1):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.suptitle(\"label \" + str(label[0]), fontsize=30)\n",
    "        plt.imshow(sequence[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 3, 2048, 1024) (2, 2) (2, 1)\n",
      "(2, 1, 3, 2048, 1024) (2, 2) (2, 1)\n",
      "(2, 1, 3, 2048, 1024) (2, 2) (2, 1)\n",
      "(2, 1, 3, 2048, 1024) (2, 2) (2, 1)\n",
      "(2, 1, 3, 2048, 1024) (2, 2) (2, 1)\n"
     ]
    }
   ],
   "source": [
    "ITER = 5\n",
    "for i in range(ITER):\n",
    "    sequences_out, shapes, start_frame_num = pipe.run()\n",
    "    sequences_out = sequences_out.as_cpu().as_array()\n",
    "    shapes = shapes.as_cpu().as_array()\n",
    "    start_frame_num = start_frame_num.as_cpu().as_array()\n",
    "    print(sequences_out.shape, shapes.shape, start_frame_num.shape)\n",
    "    # show_sequence(sequences_out[0], start_frame_num[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1080, 1920],\n",
       "       [1080, 1920]], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array([1]).item()\n",
    "# pipe = simple_pipeline(filenames=filenames[:16], labels=list(range(len(filenames[:16]))), r_width=2048, r_height=1024, batch_size=max_batch_size, num_threads=1, device_id=0)\n",
    "video_name = '../test-video-fixed-framerate.mp4'\n",
    "video_name = '/mnt/c/Users/Vlad/Desktop/ny-guiderails/test-video-from-images.mp4'\n",
    "video_name = '../test.mp4'\n",
    "pipe = video_pipe(video_name, sequence_length=8, initial_prefetch_size=16, num_threads=1, batch_size=8, device_id=0)\n",
    "pipe.build()\n",
    "res = pipe.run()\n",
    "layout\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_images(image_batch):\n",
    "    columns = 4\n",
    "    rows = (max_batch_size + 1) // (columns)\n",
    "    fig = plt.figure(figsize = (32,(32 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows*columns):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image_batch.at(j))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
